{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8643e9b-fdc8-4cf1-935f-863b98f4e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/was966/micromamba/envs/responder/bin/python\n",
    "#sbatch --mem 64G -c 12 -t 100:00:00 -p priority  ./ctct_run_all.py\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white', font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/was966/Research/mims-conceptor/')\n",
    "from baseline.immnue_score import immnue_score_methods\n",
    "from conceptor.utils import plot_embed_with_label,plot_performance, score, score2\n",
    "\n",
    "\n",
    "def onehot(S):\n",
    "    assert type(S) == pd.Series, 'Input type should be pd.Series'\n",
    "    dfd = pd.get_dummies(S, dummy_na=True)\n",
    "    nanidx = dfd[dfd[np.nan].astype(bool)].index\n",
    "    dfd.loc[nanidx, :] = np.nan\n",
    "    dfd = dfd.drop(columns=[np.nan])*1.\n",
    "    cols = dfd.sum().sort_values(ascending=False).index.tolist()\n",
    "    dfd = dfd[cols]\n",
    "    return dfd\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/was966/Research/mims-conceptor/')\n",
    "from baseline.immnue_score import immnue_score_methods\n",
    "from conceptor.utils import plot_embed_with_label,plot_performance, score\n",
    "\n",
    "data_path = '../../../../paper/00_data/'\n",
    "df_label = pd.read_pickle(os.path.join(data_path, 'ITRP.PATIENT.TABLE'))\n",
    "df_tpm = pd.read_pickle(os.path.join(data_path, 'ITRP.TPM.TABLE'))\n",
    "df_tpm.shape, df_label.shape\n",
    "\n",
    "\n",
    "df_task = onehot(df_label.response_label)\n",
    "size = df_label.groupby('cohort').size()\n",
    "size = size.index + \"\\n(n = \" + size.astype(str) + \")\"\n",
    "cohorts = df_label.groupby('cohort').size().sort_values().index.tolist()\n",
    "cohorts\n",
    "\n",
    "\n",
    "## for TIDE input\n",
    "cohort_cancer_map = {'Allen': 'SKCM','Choueiri': 'KIRC', 'Gide': 'SKCM', 'Hugo': 'SKCM',\n",
    "                     'IMVigor210': 'BLCA', 'IMmotion150': 'KIRC', 'Kim': 'STAD',\n",
    "                     'Liu': 'SKCM', 'MGH': 'SKCM', 'Miao': 'KIRC', 'Riaz': 'SKCM', \n",
    "                     'Rose': 'BLCA', 'SU2CLC1': 'LUAD', 'SU2CLC2': 'LUSC',\n",
    "                     'Snyder': 'BLCA', 'Zhao': 'GBM'}\n",
    "\n",
    "## for NetBio input\n",
    "cohort_target_map = {'Allen': 'CTLA4','Choueiri': 'PD1', 'Gide': 'PD1_CTLA4',\n",
    "                     'Hugo': 'PD1', 'IMVigor210': 'PDL1', 'IMmotion150': 'PDL1',\n",
    "                     'Kim': 'PD1', 'Liu': 'PD1', 'MGH':  'PD1_CTLA4',\n",
    "                     'Miao': 'PD1_PDL1_CTLA4', 'Riaz': 'PD1', 'Rose': 'PD1_PDL1_CTLA4',\n",
    "                     'SU2CLC1': 'PD1', 'SU2CLC2': 'PD1_PDL1_CTLA4',\n",
    "                     'Snyder': 'PDL1', 'Zhao': 'PD1'}\n",
    "\n",
    "\n",
    "def leave_one_cohort_out(cohorts):\n",
    "    # Create a list of lists, each missing one element from the original list\n",
    "    return [(cohorts[i], cohorts[:i] + cohorts[i+1:]) for i in range(len(cohorts))]\n",
    "train_test_cohorts = leave_one_cohort_out(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb6eb0-bd06-4224-b05a-199d976f7400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mode in immnue_score_methods.keys():\n",
    "\n",
    "    print('Evaludation on Model %s' % mode)\n",
    "    \n",
    "    work_dir = './LOCO/LOCO_%s' % (mode)\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "\n",
    "    res = []\n",
    "    for test_cohort, train_cohorts in train_test_cohorts:\n",
    "\n",
    "        train_cohort_name = 'Leave_%s_out' % test_cohort\n",
    "        ## Get data for this cohort\n",
    "        cohort_idx = df_label[df_label['cohort'].isin(train_cohorts)].index\n",
    "        cohort_X = df_tpm.loc[cohort_idx]\n",
    "        cohort_y = df_task.loc[cohort_idx]\n",
    "        \n",
    "        ## Get features for specific method, as of the training cohorts are mixed cancers, targets,\n",
    "        ## We use the cancer type and drug target same as the test cohort\n",
    "        cohort_target = cohort_target_map[test_cohort]\n",
    "        cohort_cancer_type = cohort_cancer_map[test_cohort]\n",
    "        \n",
    "        Extractor = immnue_score_methods[mode]\n",
    "        E = Extractor(cancer_type=cohort_cancer_type, drug_target=cohort_target)\n",
    "        cohort_dfx = E(cohort_X)\n",
    "        cohort_dfy = cohort_y['R']\n",
    "    \n",
    "        data_scaler = StandardScaler()\n",
    "        train_X = data_scaler.fit_transform(cohort_dfx)\n",
    "        train_y = cohort_dfy.values\n",
    "\n",
    "        #print(train_X.shape)\n",
    "        param_grid = {'penalty':['l2'], 'max_iter':[int(1e10)], 'solver':['lbfgs'],\n",
    "                      'C':np.arange(0.1, 1, 0.1), 'class_weight':['balanced'] }\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "        gcv = GridSearchCV(model, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1).fit(train_X, train_y)\n",
    "        best_C = gcv.best_params_['C']\n",
    "\n",
    "        test_cohort_idx = df_label[df_label['cohort'] == test_cohort].index\n",
    "        test_cohort_X = df_tpm.loc[test_cohort_idx]\n",
    "        test_cohort_y = df_task.loc[test_cohort_idx]\n",
    "        \n",
    "        test_cohort_dfx = E(test_cohort_X)\n",
    "        test_cohort_dfy = test_cohort_y['R']\n",
    "        test_X = data_scaler.transform(test_cohort_dfx)\n",
    "        \n",
    "        pred_prob = gcv.best_estimator_.predict_proba(test_X)\n",
    "        \n",
    "        pred_testy = pd.DataFrame(pred_prob, index = test_cohort_dfy.index)\n",
    "        pred_testy['train_cohort'] = train_cohort_name\n",
    "        pred_testy['test_cohort'] = test_cohort    \n",
    "        pred_testy['best_C'] = best_C\n",
    "        pred_testy['mode'] = mode\n",
    "        dfp = test_cohort_y.join(pred_testy)\n",
    "\n",
    "        y_true, y_prob, y_pred = dfp['R'], dfp[1], dfp[[0, 1]].idxmax(axis=1)\n",
    "        fig = plot_performance(y_true, y_prob, y_pred)\n",
    "        fig.suptitle('cohort to cohort transfer: train: %s, test: %s' % (train_cohort_name, test_cohort), fontsize=16)\n",
    "        fig.savefig(os.path.join(work_dir, 'CTCT_train_%s_test_%s.jpg' % (train_cohort_name, test_cohort)))\n",
    "        res.append(dfp)\n",
    "\n",
    "    dfs = pd.concat(res)\n",
    "    dfp = dfs.groupby(['train_cohort', 'test_cohort']).apply(lambda x:score2(x['R'], x[1], x[[0, 1]].idxmax(axis=1)))\n",
    "    mode_map = dfs.groupby('train_cohort')['mode'].unique().apply(lambda x:x[0])\n",
    "    c_map = dfs.groupby('train_cohort')['best_C'].unique().apply(lambda x:x[0])\n",
    "    \n",
    "    #roc, prc, f1, acc, mcc\n",
    "    dfp = dfp.apply(pd.Series)\n",
    "    dfp.columns = ['ROC', 'PRC', 'F1', 'ACC', 'MCC']\n",
    "    dfp = dfp.reset_index()\n",
    "    dfp['mode'] = dfp.train_cohort.map(mode_map)\n",
    "    dfp['best_C'] = dfp.train_cohort.map(c_map)\n",
    "    \n",
    "    dfs.to_csv(os.path.join(work_dir, 'source_performance.tsv'), sep='\\t')\n",
    "    dfp.to_csv(os.path.join(work_dir, 'metric_performance.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c456c5ea-3b26-40ca-ab77-9e2b2e83f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mLOCO\u001b[0m/  LOCO_run_all.ipynb  LOCO_run_all.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7c5b2-08ec-4ffa-aecb-9b51247fdc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
