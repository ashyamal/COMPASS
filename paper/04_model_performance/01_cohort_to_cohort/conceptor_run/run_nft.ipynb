{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c64883-0781-4fc3-9d5c-a2de7ce6d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/was966/micromamba/envs/responder/bin/python\n",
    "#sbatch --mem 64G -c 4 -t 100:00:00 -p gpu_quad --gres=gpu:rtx8000:1 ./loo_fft_dense16.py\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/was966/Research/mims-conceptor/')\n",
    "from conceptor.utils import plot_embed_with_label\n",
    "from conceptor import PreTrainer, FineTuner, loadconceptor #, get_minmal_epoch\n",
    "from conceptor.utils import plot_embed_with_label,plot_performance, score2\n",
    "from conceptor.tokenizer import CANCER_CODE\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white', font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def onehot(S):\n",
    "    assert type(S) == pd.Series, 'Input type should be pd.Series'\n",
    "    dfd = pd.get_dummies(S, dummy_na=True)\n",
    "    nanidx = dfd[dfd[np.nan].astype(bool)].index\n",
    "    dfd.loc[nanidx, :] = np.nan\n",
    "    dfd = dfd.drop(columns=[np.nan])*1.\n",
    "    cols = dfd.sum().sort_values(ascending=False).index.tolist()\n",
    "    dfd = dfd[cols]\n",
    "    return dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f073864-d64b-44c8-b3d0-b9ebbc7f71f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 71/71 [00:04<00:00, 14.33it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrainer = loadconceptor('../../../checkpoint/latest/pretrainer.pt')\n",
    "data_path = '../../../../paper/00_data/'\n",
    "df_label = pd.read_pickle(os.path.join(data_path, 'ITRP.PATIENT.TABLE'))\n",
    "df_tpm = pd.read_pickle(os.path.join(data_path, 'ITRP.TPM.TABLE'))\n",
    "df_tpm.shape, df_label.shape\n",
    "\n",
    "\n",
    "dfcx = df_label.cancer_type.map(CANCER_CODE).to_frame('cancer_code').join(df_tpm)\n",
    "_, dfx = pretrainer.extract(dfcx, batch_size=16)\n",
    "dfy = df_label.response_label\n",
    "\n",
    "size = df_label.groupby('cohort').size()\n",
    "size = size.index + \"\\n(n = \" + size.astype(str) + \")\"\n",
    "cohorts = df_label.groupby('cohort').size().sort_values().index.tolist()\n",
    "#cohorts = ['Choueiri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e3182-7ba2-40e4-a030-458ba58e3ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95af3dc3-e2ea-4f9b-b017-0b60d1e512a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohort_to_cohort(cohorts):\n",
    "    # Create a list of lists, each missing one element from the original list\n",
    "    return [(cohorts[i], cohorts[:i] + cohorts[i+1:]) for i in range(len(cohorts))]\n",
    "train_test_cohorts = cohort_to_cohort(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fde188-ad64-46d2-baa0-9c73d4737366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conceptor.decoder import ProtoNetNFTDecoder\n",
    "\n",
    "scols = dfcx.columns\n",
    "dfx_used = dfcx[scols]\n",
    "\n",
    "mode = 'NFT'\n",
    "seed = 42\n",
    "work_dir = './CTCT/CTCT_%s_%s' % (mode, seed)\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f4717a-e977-4ab2-b778-2c10aa496f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 15674)\n",
      "(17, 15674)\n",
      "(21, 15674)\n",
      "(25, 15674)\n",
      "(25, 15674)\n",
      "(26, 15674)\n",
      "(34, 15674)\n",
      "(39, 15674)\n",
      "(45, 15674)\n",
      "(51, 15674)\n",
      "(73, 15674)\n",
      "(89, 15674)\n",
      "(102, 15674)\n",
      "(107, 15674)\n",
      "(165, 15674)\n",
      "(298, 15674)\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for train_cohort, test_cohorts in train_test_cohorts:\n",
    "    \n",
    "    ## Get data for this cohort\n",
    "    cohort_idx = df_label[df_label['cohort'] == train_cohort].index\n",
    "    cohort_X = dfcx.loc[cohort_idx]\n",
    "    cohort_y = dfy.loc[cohort_idx]\n",
    "\n",
    "    \n",
    "    ## Get features for specific method\n",
    "    train_X = cohort_X\n",
    "    train_y = cohort_y\n",
    "    \n",
    "    support_set = train_X.join(train_y)\n",
    "    print(support_set.shape)\n",
    "    \n",
    "    NFT = ProtoNetNFTDecoder()\n",
    "    NFT = NFT.fit(support_set)\n",
    "    \n",
    "    for test_cohort in cohorts:\n",
    "        test_cohort_idx = df_label[df_label['cohort'] == test_cohort].index\n",
    "        test_cohort_X = dfcx.loc[test_cohort_idx]\n",
    "        test_cohort_y = dfy.loc[test_cohort_idx]\n",
    "\n",
    "        query_set = test_cohort_X.join(test_cohort_y)\n",
    "        pred_testy = NFT.transform(query_set)\n",
    "\n",
    "        pred_testy['train_cohort'] = train_cohort\n",
    "        pred_testy['test_cohort'] = test_cohort \n",
    "        \n",
    "        pred_testy['best_epoch'] = 0\n",
    "        pred_testy['n_trainable_params'] = 0\n",
    "        pred_testy['mode'] = mode\n",
    "        pred_testy['seed'] = seed\n",
    "        pred_testy['batch_size'] = np.nan\n",
    "        pred_testy['task_dense_layer'] = np.nan\n",
    "        #dfp = test_cohort_y.join(pred_testy)\n",
    "    \n",
    "        dfp = onehot(test_cohort_y.map({'PD':'NR', 'PR':'R',\n",
    "                                   'SD':'NR', 'CR':'R',\n",
    "                                   'NR':'NR', 'R':'R'})).join(pred_testy)\n",
    "    \n",
    "        # y_true, y_prob, y_pred = dfp['R'], dfp[1], dfp[[0, 1]].idxmax(axis=1)\n",
    "        # fig = plot_performance(y_true, y_prob, y_pred)\n",
    "        # fig.suptitle('cohort to cohort transfer: train: %s, test: %s' % (train_cohort, test_cohort), fontsize=16)\n",
    "        # fig.savefig(os.path.join(work_dir, 'CTCT_train_%s_test_%s.jpg' % (train_cohort, test_cohort)))\n",
    "        res.append(dfp)\n",
    "\n",
    "dfs = pd.concat(res)\n",
    "dfp = dfs.groupby(['train_cohort', 'test_cohort']).apply(lambda x:score2(x['R'], x[1], x[[0, 1]].idxmax(axis=1)))\n",
    "\n",
    "\n",
    "#roc, prc, f1, acc, mcc\n",
    "dfp = dfp.apply(pd.Series)\n",
    "dfp.columns = ['ROC', 'PRC', 'F1', 'ACC', 'MCC']\n",
    "dfp = dfp.reset_index()\n",
    "\n",
    "dfs.to_csv(os.path.join(work_dir, 'source_performance.tsv'), sep='\\t')\n",
    "dfp.to_csv(os.path.join(work_dir, 'metric_performance.tsv'), sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750eb1f-cdaa-45d7-b6a3-254c31c330a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ac848-8e5b-4aa7-93b3-fb350c44f8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506c68d-5571-47cd-8a2e-d3203d5fa7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a74db-3580-4a8f-81a1-76ee4db11cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0f4ae-2d14-4bb4-94b0-12cc247a4e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
