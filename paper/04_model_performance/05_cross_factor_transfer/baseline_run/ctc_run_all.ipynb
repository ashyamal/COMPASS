{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb8793e4-40b4-4d73-b1e5-704959b5c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/was966/micromamba/envs/responder/bin/python\n",
    "#sbatch --mem 64G -c 12 -t 100:00:00 -p priority  ./ctct_run_all.py\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white', font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/was966/Research/mims-conceptor/')\n",
    "from baseline.immnue_score import immnue_score_methods\n",
    "from conceptor.utils import plot_embed_with_label,plot_performance, score, score2\n",
    "\n",
    "\n",
    "def onehot(S):\n",
    "    assert type(S) == pd.Series, 'Input type should be pd.Series'\n",
    "    dfd = pd.get_dummies(S, dummy_na=True)\n",
    "    nanidx = dfd[dfd[np.nan].astype(bool)].index\n",
    "    dfd.loc[nanidx, :] = np.nan\n",
    "    dfd = dfd.drop(columns=[np.nan])*1.\n",
    "    cols = dfd.sum().sort_values(ascending=False).index.tolist()\n",
    "    dfd = dfd[cols]\n",
    "    return dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdaf9b9-dc37-4478-8182-97048c625303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/was966/Research/mims-conceptor/')\n",
    "from baseline.immnue_score import immnue_score_methods\n",
    "from conceptor.utils import plot_embed_with_label,plot_performance, score\n",
    "\n",
    "data_path = '../../../../paper/00_data/'\n",
    "df_label = pd.read_pickle(os.path.join(data_path, 'ITRP.PATIENT.TABLE'))\n",
    "df_tpm = pd.read_pickle(os.path.join(data_path, 'ITRP.TPM.TABLE'))\n",
    "df_tpm.shape, df_label.shape\n",
    "\n",
    "df_task = onehot(df_label.response_label)\n",
    "size = df_label.groupby('cohort').size()\n",
    "size = size.index + \"\\n(n = \" + size.astype(str) + \")\"\n",
    "cohorts = df_label.groupby('cohort').size().sort_values().index.tolist()\n",
    "#cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2bcd4f-f20c-46d2-9da4-459280dd0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c2c = pd.read_csv('../stratification/cancer2cancer.csv', index_col=0)\n",
    "df_d2d = pd.read_csv('../stratification/drug2drug.csv', index_col=0)\n",
    "df_s2s = pd.read_csv('../stratification/sequencer2sequencer.csv', index_col=0)\n",
    "\n",
    "df_label = pd.concat([df_c2c, df_d2d, df_s2s])\n",
    "cohorts = df_label['stratified_cohort'].unique().tolist()\n",
    "cohort_rgc = df_label[['stratified_cohort', 'stratified_cohort_rgc']].drop_duplicates().set_index('stratified_cohort').stratified_cohort_rgc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a1637-cbde-4769-878f-3cfe257c1ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d47ed3-6d2e-4aef-9d76-00279c0a8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_target_map = df_label[['stratified_cohort', 'ICI_target_map']].drop_duplicates().set_index('stratified_cohort').ICI_target_map.to_dict()\n",
    "cohort_cancer_map = df_label[['stratified_cohort', 'cancer_type']].drop_duplicates().set_index('stratified_cohort').cancer_type.to_dict()\n",
    "\n",
    "def cohort_to_cohort(cohorts):\n",
    "    # Create a list of lists, each missing one element from the original list\n",
    "    return [(cohorts[i], cohorts[:i] + cohorts[i+1:]) for i in range(len(cohorts))]\n",
    "# train_test_cohorts = cohort_to_cohort(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22e5d4f-9f52-4481-ab3c-544152e00d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_groups = df_label.groupby(['domain', 'group'])['stratified_cohort'].unique().apply(lambda x:x.tolist())\n",
    "\n",
    "train_test_cohorts = []\n",
    "domains = []\n",
    "groups = []\n",
    "for (domain, group), transfer_cohots in transfer_groups.items():\n",
    "    transfer_pairs = cohort_to_cohort(transfer_cohots)\n",
    "    for pair in transfer_pairs:\n",
    "        domains.append(domain)\n",
    "        groups.append(group)\n",
    "        train_test_cohorts.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487423e-9c26-46eb-8aeb-381438f7461c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mode in immnue_score_methods.keys():\n",
    "\n",
    "    print('Evaluation on Model %s' % mode)\n",
    "    \n",
    "    work_dir = './F2F/F2F_%s' % (mode)\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "\n",
    "    res = []\n",
    "    for (train_cohort, test_cohorts), domain, group in zip(train_test_cohorts, domains, groups):\n",
    "        \n",
    "        ## Get data for this cohort\n",
    "        cohort_idx = df_label[df_label['stratified_cohort'] == train_cohort].index\n",
    "        cohort_X = df_tpm.loc[cohort_idx]\n",
    "        cohort_y = df_task.loc[cohort_idx]\n",
    "        \n",
    "        ## Get features for specific method\n",
    "        cohort_target = cohort_target_map[train_cohort]\n",
    "        cohort_cancer_type = cohort_cancer_map[train_cohort]\n",
    "        Extractor = immnue_score_methods[mode]\n",
    "        E = Extractor(cancer_type=cohort_cancer_type, drug_target=cohort_target)\n",
    "        cohort_dfx = E(cohort_X)\n",
    "        cohort_dfy = cohort_y['R']\n",
    "    \n",
    "        data_scaler = StandardScaler()\n",
    "        train_X = data_scaler.fit_transform(cohort_dfx)\n",
    "        train_y = cohort_dfy.values\n",
    "        \n",
    "        param_grid = {'penalty':['l2'], 'max_iter':[int(1e10)], 'solver':['lbfgs'],\n",
    "                      'C':np.arange(0.1, 1, 0.1), 'class_weight':['balanced'] }\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "        gcv = GridSearchCV(model, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1).fit(train_X, train_y)\n",
    "        best_C = gcv.best_params_['C']\n",
    "    \n",
    "        for test_cohort in test_cohorts:\n",
    "            test_cohort_idx = df_label[df_label['stratified_cohort'] == test_cohort].index\n",
    "            test_cohort_X = df_tpm.loc[test_cohort_idx]\n",
    "            test_cohort_y = df_task.loc[test_cohort_idx]\n",
    "            \n",
    "            test_cohort_dfx = E(test_cohort_X)\n",
    "            test_cohort_dfy = test_cohort_y['R']\n",
    "            test_X = data_scaler.transform(test_cohort_dfx)\n",
    "            \n",
    "            pred_prob = gcv.best_estimator_.predict_proba(test_X)\n",
    "            \n",
    "            pred_testy = pd.DataFrame(pred_prob, index = test_cohort_dfy.index)\n",
    "\n",
    "            pred_testy['domain'] = domain\n",
    "            pred_testy['group'] = group\n",
    "            pred_testy['train_cohort'] = train_cohort\n",
    "            pred_testy['test_cohort'] = test_cohort    \n",
    "            pred_testy['test_cohort_rgc'] = cohort_rgc[test_cohort]\n",
    "            \n",
    "            pred_testy['best_C'] = best_C\n",
    "            pred_testy['mode'] = mode\n",
    "            \n",
    "            dfp = test_cohort_y.join(pred_testy)\n",
    "    \n",
    "            y_true, y_prob, y_pred = dfp['R'], dfp[1], dfp[[0, 1]].idxmax(axis=1)\n",
    "            fig = plot_performance(y_true, y_prob, y_pred)\n",
    "            fig.suptitle('train: %s, test: %s' % (train_cohort, test_cohort), fontsize=16)\n",
    "            fig.savefig(os.path.join(work_dir, 'CTCT_train_%s_test_%s.jpg' % (train_cohort.replace('/', ':'), test_cohort.replace('/', ':'))))\n",
    "            res.append(dfp)\n",
    "    \n",
    "    dfs = pd.concat(res)\n",
    "    dfp = dfs.groupby(['domain','group','train_cohort', 'test_cohort', 'mode', 'best_C', 'test_cohort_rgc']).apply(lambda x:score2(x['R'], x[1], x[[0, 1]].idxmax(axis=1)))\n",
    "    \n",
    "    #roc, prc, f1, acc, mcc\n",
    "    dfp = dfp.apply(pd.Series)\n",
    "    dfp.columns = ['ROC', 'PRC', 'F1', 'ACC', 'MCC']\n",
    "    dfp = dfp.reset_index()\n",
    "\n",
    "    dfs.to_csv(os.path.join(work_dir, 'source_performance.tsv'), sep='\\t')\n",
    "    dfp.to_csv(os.path.join(work_dir, 'metric_performance.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49037b3f-afb6-4b36-9f5e-3bfd423782f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ab970-0ada-4576-b09e-be0faccfe6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820fa9e-eee4-4d61-af5b-ff954c67bcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd961195-23a5-46da-91df-380f678af06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
