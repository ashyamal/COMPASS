{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750dc21-4acf-4e83-8414-c0e51759a30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaludation on Model PFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 50/50 [04:19<00:00,  5.19s/it]\n",
      "100%|##########| 33/33 [00:01<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaludation on Model PFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|######6   | 33/50 [02:48<01:27,  5.14s/it]"
     ]
    }
   ],
   "source": [
    "#!/home/was966/micromamba/envs/responder/bin/python\n",
    "#sbatch --mem 64G -c 4 -t 100:00:00 -p gpu_quad --gres=gpu:teslaV100s:1 ./pft_leave_drug.py\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/was966/Research/mims-compass/')\n",
    "from compass.utils import plot_embed_with_label\n",
    "from compass import PreTrainer, FineTuner, loadcompass #, get_minmal_epoch\n",
    "from compass.utils import plot_embed_with_label,plot_performance, score2\n",
    "from compass.tokenizer import CANCER_CODE\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white', font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def onehot(S):\n",
    "    assert type(S) == pd.Series, 'Input type should be pd.Series'\n",
    "    dfd = pd.get_dummies(S, dummy_na=True)\n",
    "    nanidx = dfd[dfd[np.nan].astype(bool)].index\n",
    "    dfd.loc[nanidx, :] = np.nan\n",
    "    dfd = dfd.drop(columns=[np.nan])*1.\n",
    "    cols = dfd.sum().sort_values(ascending=False).index.tolist()\n",
    "    dfd = dfd[cols]\n",
    "    return dfd\n",
    "\n",
    "\n",
    "\n",
    "pretrainer = loadcompass('../../../checkpoint/latest/pretrainer.pt')\n",
    "data_path = '../../../00_data/'\n",
    "df_label = pd.read_pickle(os.path.join(data_path, 'ITRP.PATIENT.TABLE'))\n",
    "df_tpm = pd.read_pickle(os.path.join(data_path, 'ITRP.TPM.TABLE'))\n",
    "df_tpm.shape, df_label.shape\n",
    "\n",
    "dfcx = df_label.cancer_type.map(CANCER_CODE).to_frame('cancer_code').join(df_tpm)\n",
    "\n",
    "df_task = onehot(df_label.response_label)\n",
    "size = df_label.groupby('cohort').size()\n",
    "size = size.index + \"\\n(n = \" + size.astype(str) + \")\"\n",
    "\n",
    "factor = 'ICI_map'\n",
    "\n",
    "cohort_size = df_label.groupby(factor).size()\n",
    "cohorts = cohort_size[cohort_size > 10].sort_values().index.tolist()\n",
    "\n",
    "\n",
    "def leave_one_cohort_out(cohorts):\n",
    "    # Create a list of lists, each missing one element from the original list\n",
    "    return [(cohorts[i], cohorts[:i] + cohorts[i+1:]) for i in range(len(cohorts))]\n",
    "train_test_cohorts = leave_one_cohort_out(cohorts)\n",
    "train_test_cohorts = [('Atezo', ['Ipi+Nivo', 'Ipi+Pembro', 'Uknow', 'Ipi', 'Nivo', 'Pembro'])]\n",
    "\n",
    "params = {'mode': 'PFT',\n",
    "        'seed':42,\n",
    "        'lr': 1e-3,\n",
    "        'device':'cuda',\n",
    "        'weight_decay': 1e-4,\n",
    "        'batch_size':64, \n",
    "        'max_epochs': 50,\n",
    "        'task_loss_weight':1,\n",
    "        'load_decoder':False,\n",
    "        'task_loss_type': 'ce_loss', \n",
    "        'task_type': 'c',\n",
    "        'task_dense_layer': [16],\n",
    "        'task_batch_norms':True,\n",
    "        'entropy_weight': 0.0,\n",
    "        'with_wandb': False,\n",
    "        'save_best_model':False,\n",
    "        'verbose': False}\n",
    "\n",
    "\n",
    "seed = 42\n",
    "for seed in [24, 42, 64,]:\n",
    "    for mode in ['PFT']: #,\n",
    "    \n",
    "        print('Evaludation on Model %s' % mode)\n",
    "    \n",
    "        params['mode'] = mode\n",
    "        params['seed'] = seed\n",
    "        \n",
    "        work_dir = './Test_Atezo/%s_%s' % (mode, seed)\n",
    "        # if not os.path.exists(work_dir):\n",
    "        #     os.makedirs(work_dir)\n",
    "        \n",
    "        res = []\n",
    "        for test_cohort, train_cohorts in train_test_cohorts:\n",
    "    \n",
    "            train_cohort_name = 'Leave_%s_out' % test_cohort\n",
    "    \n",
    "    \n",
    "            test_cohort_idx = df_label[df_label[factor] == test_cohort].index\n",
    "            test_cohort_X = dfcx.loc[test_cohort_idx]\n",
    "            test_cohort_y = df_task.loc[test_cohort_idx]\n",
    "    \n",
    "            \n",
    "            ## Get data for this cohort\n",
    "            cohort_idx = df_label[df_label[factor] != test_cohort].index\n",
    "            cohort_X = dfcx.loc[cohort_idx]\n",
    "            cohort_y = df_task.loc[cohort_idx]\n",
    "    \n",
    "            \n",
    "            ## Get features for specific method\n",
    "            train_X = cohort_X\n",
    "            train_y = cohort_y\n",
    "            \n",
    "            pretrainer = pretrainer.copy()\n",
    "            finetuner = FineTuner(pretrainer, **params, \n",
    "                                  work_dir= work_dir, \n",
    "                                  task_name = '%s' % train_cohort_name)\n",
    "            \n",
    "            finetuner = finetuner.tune(dfcx_train = train_X,\n",
    "                                       dfy_train = train_y, min_mcc=0.8)\n",
    "    \n",
    "    \n",
    "            _, pred_testy = finetuner.predict(test_cohort_X, batch_size = 16)\n",
    "    \n",
    "            pred_testy['train_cohort'] = train_cohort_name\n",
    "            pred_testy['test_cohort'] = test_cohort \n",
    "            \n",
    "            pred_testy['best_epoch'] = finetuner.best_epoch\n",
    "            pred_testy['n_trainable_params'] = finetuner.count_parameters()\n",
    "            pred_testy['mode'] = mode\n",
    "            pred_testy['seed'] = seed\n",
    "            pred_testy['batch_size'] = params['batch_size']\n",
    "            pred_testy['task_dense_layer'] = str(params['task_dense_layer'])\n",
    "            dfp = test_cohort_y.join(pred_testy)\n",
    "    \n",
    "            y_true, y_prob, y_pred = dfp['R'], dfp[1], dfp[[0, 1]].idxmax(axis=1)\n",
    "            fig = plot_performance(y_true, y_prob, y_pred)\n",
    "            fig.suptitle('cohort to cohort transfer: train: %s, test: %s' % (train_cohort_name, test_cohort), fontsize=16)\n",
    "            #fig.savefig(os.path.join(work_dir, 'CTCT_train_%s_test_%s.jpg' % (train_cohort_name, test_cohort)))\n",
    "            res.append(dfp)\n",
    "        \n",
    "        dfs = pd.concat(res)\n",
    "        dfp = dfs.groupby(['train_cohort', 'test_cohort']).apply(lambda x:score2(x['R'], x[1], x[[0, 1]].idxmax(axis=1)))\n",
    "    \n",
    "        #roc, prc, f1, acc, mcc\n",
    "        dfp = dfp.apply(pd.Series)\n",
    "        dfp.columns = ['ROC', 'PRC', 'F1', 'ACC', 'MCC']\n",
    "        dfp = dfp.reset_index()\n",
    "        \n",
    "        #dfs.to_csv(os.path.join(work_dir, 'source_performance.tsv'), sep='\\t')\n",
    "        #dfp.to_csv(os.path.join(work_dir, 'metric_performance.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e3724-9a43-4c80-bf59-cfabc11c79ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ea9b1-3e1d-424d-9d4d-e2874a40c90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
